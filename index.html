<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<title>History of Computing</title>
	<link rel="stylesheet" href="styles/main.css">
	<meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
	<header>
		<h1>History of Computing</h1>
		<nav>
			<button onclick="showSection('home')">Home</button>
			<button onclick="showSection('timeline')">Timeline</button>
			<button onclick="showSection('people')">Signifigant People</button>
			<button id="themeToggle">Dyslexia mode</button>

		</nav>
	</header>

	<section id="home">
		<div class="container">
			<div class="homeIntro" <p>
				Computers have shaped the modern world, transforming how we communicate,
				work, play, and accomplish tasks across nearly every area of life. From business to
				education and entertainment to science, their impact is undeniable. These machines have
				not
				only increased our efficiency but also opened up entirely new possibilities that were
				once unimaginable. Their influence stretches across every part of our daily
				routines—from quick online searches and digital banking to virtual meetings and global
				research collaboration. To truly appreciate the immense power and potential of
				computers, it's essential to look back at their humble beginnings and explore the
				remarkable journey of their evolution over time.
				</p>
			</div>

			<div class="homeParagraph">
				<img is="abacusIMG" src="images/Abacus_6.png" alt="abacus" />
				<p>
					From ancient tools like the abacus to the sophisticated digital devices we rely
					on today, the journey of computing technology has been long, rich, and
					fascinating. The abacus, for example, served as one of humanity’s earliest
					attempts at simplifying calculations, helping merchants and mathematicians
					manage numbers with ease. As time passed, inventors and thinkers began to build
					mechanical machines that could process information more efficiently. These early
					computers, while basic by today’s standards, were revolutionary for their time
					and laid the groundwork for the digital breakthroughs that would follow. Each
					step in this timeline reflects society’s growing dependence on automation and
					logic-driven tools to solve increasingly complex problems.
				</p>
			</div>

			<div class="homeParagraph">
				<img id="mapIMG" src="/images/Internet_map_1024.jpg"
					alt="A map of a portion of the internet" />
				<p>
					Today, computers and the internet grant us access to unlimited information and
					the ability to connect with people around the world in real time. With just a
					few clicks, we can attend virtual classes, video chat with friends overseas, or
					stream high-definition content on demand. The digital age has brought about an
					unprecedented level of accessibility and freedom, empowering individuals to
					learn, create, and share ideas regardless of location. Whether you're a student
					doing research or an entrepreneur running a global business, the modern internet
					is a powerful tool. The image below provides a glimpse into the massive and
					intricate web of connections that make up our global internet infrastructure, a
					system that silently powers nearly every modern convenience we now take for
					granted.
				</p>
			</div>

			<div class="homeParagraph">
				<p>
					This video offers an overview of how computing has advanced through
					history and how we arrived at the incredibly powerful tools we use today. It
					takes you through some of the major milestones, from early mechanical inventions
					to the rise of personal computers, and even touches on the rapid innovations
					that
					define the digital era we now live in. Watching this will not only give you a
					better appreciation of the technology around you, but also spark curiosity about
					what the future might hold as computers continue to evolve. Whether you're
					tech-savvy or just curious about how it all started, this visual summary is a
					great way to understand the progress we've made.
				</p>
				<video src="images/Early+Computing-+Crash+Course+Computer+Science+_231.mp4"
					type="video/mp4" controls></video>
			</div>
		</div>
	</section>



	<section id="timeline">
		<div class="ancient">
			<h3>Ancient Computing Devices</h3>
			<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Abacus_%28PSF%29.png/250px-Abacus_%28PSF%29.png"
					alt="Abacus"></p>
			<p>There are several examples of ancient computing. The earlyiet known one is the summerian <a
					href="https://en.wikipedia.org/wiki/Abacus">Abacus</a>. which kept count of
				items with stones on a wire. Another one is the <a
					href="https://en.wikipedia.org/wiki/Antikythera_mechanism">Antikythera
					mechanism</a> which is thouht the be the works oldest geared computing device
			</p>
		</div>

		<div class="middle">
			<h3>Middle Ages Computing</h3>
			<p><img src="images/Napier's_Bones.JPG" alt="napiers Bones"></p>
			<p>The Middle Ages saw several attempts at computing devices. Ramon Llull devoted a large part
				of his life to designing logical machines that, using undeniable truths, could produce
				all possible knowledge. They were never built and are mostly a though experiment. His
				work however influenced Gottfried Leibiniz, who built several calculating tools.</p>
		</div>

		<div class="babbage">
			<h3>Charles Babbage and Ada Lovelace</h3>
			<p><img src="images/250px-Babbage_Difference_Engine.jpg" alt="differance engine"></p>
			<p>the apex of early mechanical computing was the Difference Engine and Analytical Engine both
				made by <a href="https://en.wikipedia.org/wiki/Charles_Babbage">Charles Babbage</a>.
				Although neither was made, a team of engineers built a functioning Difference Engine
				using only materials from the time. Babbage&#39;s devices could be reprogrammed with
				input on punch cards. <a href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada
					Lovelace</a> wrote programs for these devices including one that calculated the
				Bernoulli numbers.</p>
		</div>

		<div class="early20th">
			<h3>Early 20th Century Mechanical Computing</h3>
			<p><img src="images/Harvard_Mark_I_Computer_-_Input-Output_Details.jpg" alt="Harvard Mark I">
			</p>
			<p>In the early 1900s, mechanical calculators like the <a
					href="https://en.wikipedia.org/wiki/Comptometer">Comptometer</a> and the <a
					href="https://en.wikipedia.org/wiki/Marchant_calculator">Marchant calculator</a>
				were widely used in business and science. During the 1930s, Konrad Zuse built the
				<strong>Z3</strong> in Germany, considered the first programmable electromechanical
				computer (1941). Around the same time, Howard Aiken and IBM developed the
				<strong>Harvard Mark I</strong>, a room-sized calculator used for U.S. Navy computations
				during World War II.
			</p>
		</div>

		<div class="turing">
			<h3>Alan Turing and Theoretical Computing</h3>
			<p><img src="images/Alan_Turing_Aged_16.jpg" alt="Alan Turing"></p>
			<p>In 1936, British mathematician <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan
					Turing</a> published a paper introducing the concept of a <strong>Turing
					machine</strong>, laying the foundation for theoretical computer science. During
				WWII, Turing worked at Bletchley Park to help break the German <strong>Enigma</strong>
				cipher, building machines like the <strong>Bombe</strong>, a pioneering code-breaking
				device.</p>
		</div>

		<div class="colossus">
			<h3>The Colossus</h3>
			<p><img src="images/LorenzSZ42at_TNMOC.jpg" alt="Colossus"></p>
			<p>Built in 1943–44, the <strong><a
						href="https://en.wikipedia.org/wiki/Colossus_computer">Colossus</a></strong>
				was the world’s first programmable electronic digital computer. It was used by British
				codebreakers to decipher German teleprinter messages encrypted with the Lorenz cipher.
				Colossus significantly reduced the time required for decryption and remained secret for
				decades after the war.</p>
		</div>

		<div class="eniac">
			<h3>ENIAC and Electronic Computing</h3>
			<p><img src="images/Glen_Beck_and_Betty_Snyder_program_the_ENIAC_in_building_328_at_the_Ballistic_Research_Laboratory.jpg"
					alt="ENIAC"></p>
			<p>Developed at the University of Pennsylvania and completed in 1945, the <strong><a
						href="https://en.wikipedia.org/wiki/ENIAC">ENIAC</a></strong> was the
				first fully electronic general-purpose computer. Created by <strong>John Presper
					Eckert</strong> and <strong>John Mauchly</strong>, it could solve a wide range
				of numerical problems, especially for military applications like artillery trajectory
				tables.</p>
		</div>

		<div class="stored">
			<h3>The Stored-Program Concept</h3>
			<p><img src="images/JohnvonNeumann-LosAlamos.gif" alt="John von Neumann"></p>
			<p>In 1945, <strong>John von Neumann</strong> proposed the <strong>stored-program
					architecture</strong>, which suggested that a computer’s program and data could
				be stored in the same memory. This model, later called the <strong>von Neumann
					architecture</strong>, became the standard for most computers. The first
				implementation of this idea was the <strong>EDVAC</strong>, followed by machines like
				<strong>EDSAC</strong> and <strong>Manchester Baby</strong>.
			</p>
		</div>

		<div class="univac">
			<h3>UNIVAC and Commercial Computing</h3>
			<p><img src="images/Univac_I_Census_dedication.jpg" alt="UNIVAC I"></p>
			<p>In 1951, <strong><a href="https://en.wikipedia.org/wiki/UNIVAC_I">UNIVAC I</a></strong>
				became the first commercial computer delivered in the United States. Also developed by
				Eckert and Mauchly, it was used by government and business clients and famously
				predicted the outcome of the 1952 U.S. presidential election live on television.</p>
		</div>

		<div class="micro">
			<h3>Integrated Circuits and the Microprocessor</h3>
			<p><img src="images/Intel_C4004.jpg" alt="Intel 4004"></p>
			<p>In the late 1950s and 1960s, engineers like <strong>Jack Kilby</strong> and <strong>Robert
					Noyce</strong> developed the <strong><a
						href="https://en.wikipedia.org/wiki/Integrated_circuit">integrated
						circuit</a></strong> (IC), allowing many transistors to be placed on a
				single chip. In 1971, <strong>Intel</strong> introduced the <strong><a
						href="https://en.wikipedia.org/wiki/Intel_4004">4004</a></strong>, the
				first commercial <strong>microprocessor</strong>, launching the era of general-purpose
				computing on a single chip.</p>
		</div>

		<div class="personal">
			<h3>The Rise of Personal Computing</h3>
			<p><img src="images/Altair_8800_Computer.jpg" alt="Altair 8800"></p>
			<p>In 1975, the <strong><a href="https://en.wikipedia.org/wiki/Altair_8800">Altair
						8800</a></strong>, often considered the first personal computer, was
				released as a kit. It inspired <strong>Bill Gates</strong> and <strong>Paul
					Allen</strong> to write a version of BASIC for it, founding
				<strong>Microsoft</strong>. Soon after, <strong>Apple Computer</strong> was formed by
				<strong>Steve Jobs</strong> and <strong>Steve Wozniak</strong>, leading to the 1977
				release of the <strong>Apple II</strong>, one of the first highly successful personal
				computers.
			</p>
		</div>

		<div class="gui">
			<h3>Graphical User Interfaces and the Mouse</h3>
			<p><img src="images/Xerox_Alto_mit_Rechner.JPG" alt="Xerox Alto"></p>
			<p>The <strong><a href="https://en.wikipedia.org/wiki/Xerox_Alto">Xerox Alto</a></strong> (1973)
				was the first computer with a <strong>graphical user interface (GUI)</strong>, using
				windows, icons, and a mouse. Though not commercially released, it influenced later
				systems. In 1984, Apple introduced the <strong>Macintosh</strong>, bringing the GUI and
				mouse to the mass market and changing how users interacted with computers.</p>
		</div>

		<div class="internet">
			<h3>The Internet and the World Wide Web</h3>
			<p><img src="images/WWW-LetShare.svg.png" alt="World Wide Web"></p>
			<p>While the <strong>Internet</strong> originated in the 1960s as <strong>ARPANET</strong>, it
				was the 1990 invention of the <strong><a
						href="https://en.wikipedia.org/wiki/Tim_Berners-Lee">World Wide
						Web</a></strong> by <strong>Tim Berners-Lee</strong> that made the
				internet accessible to the public. By the mid-1990s, web browsers like
				<strong>Netscape</strong> and <strong>Internet Explorer</strong> helped drive an
				internet boom that reshaped global communication, commerce, and culture.
			</p>
		</div>

		<div class="mobile">
			<h3>Mobile Computing and Smartphones</h3>
			<p><img src="images/IPhone_1st_Gen.svg.png" alt="iPhone"></p>
			<p>The 2000s saw computing become portable and personal. <strong>Laptops</strong> became
				widespread, and in 2007, Apple released the first <strong><a
						href="https://en.wikipedia.org/wiki/IPhone_\(1st_generation\">iPhone</a>)</strong>,
				revolutionizing mobile computing. Smartphones combined computing power with connectivity
				and sensors, leading to the rise of apps, location services, and cloud-based personal
				assistants.</p>
		</div>

		<div class="cloud">
			<h3>Cloud Computing and Big Data</h3>
			<p><img src="images/Cloud_computing.svg.png" alt="Server Farm"></p>
			<p>With the rise of <strong><a href="https://en.wikipedia.org/wiki/Cloud_computing">cloud
						computing</a></strong> in the 2010s, services like <strong>Amazon Web
					Services (AWS)</strong>, <strong>Google Cloud</strong>, and <strong>Microsoft
					Azure</strong> allowed data and software to be hosted remotely and accessed
				globally. This enabled <strong>big data analytics</strong>, <strong>machine
					learning</strong>, and scalable computing for businesses and developers.</p>
		</div>

		<div class="ai">
			<h3>Artificial Intelligence and Machine Learning</h3>
			<p><img src="images/Artificial_neural_network.svg.png" alt="Nural Network"></p>
			<p>Advances in hardware and algorithms have led to a boom in <strong>artificial intelligence
					(AI)</strong>. Systems like <strong>IBM Watson</strong>,
				<strong>AlphaGo</strong>, and most recently <strong>ChatGPT</strong> have demonstrated
				the power of deep learning and large-scale neural networks. AI now powers everything
				from voice assistants to real-time translation and medical diagnostics.
			</p>
		</div>
	</section>


	<section id="people">

		<h1>Significant People in Computer Science History</h1>

		<div class="person">
			<div>
				<h2>Ada Lovelace</h2>
				<figure>
					<img src="images/Ada_Lovelace_daguerreotype_by_Antoine_Claudet_1843_-_cropped.png"
						alt="Daguerreotype of Ada Lovelace">
					<figcaption>Daguerreotype of Ada Lovelace</figcaption>
				</figure>
			</div>
			<p><strong>First Computer Programmer:</strong> Ada Lovelace, born in 1815, is recognized as the
				first computer programmer. She collaborated with Charles Babbage on his proposed
				Analytical Engine. Her notes included what is considered the first algorithm designed to
				be carried out by a machine, and she envisioned computers doing much more than
				calculations.</p>
		</div>

		<div class="person">
			<div>
				<h2>Alan Turing</h2>
				<figure>
					<img src="images/Alan_Turing_Aged_16.jpg" alt="Alan Turing in 1951">
					<figcaption>Alan Turing in 1951</figcaption>
				</figure>
			</div>
			<p><strong>Father of Modern Computing:</strong> Alan Turing's work laid the foundation for
				theoretical computer science and artificial intelligence. He developed the concept of
				the Turing machine and played a critical role in breaking the Enigma code during WWII.
				He also proposed the "Turing Test" to evaluate a machine's ability to exhibit
				intelligent behavior.</p>
		</div>

		<div class="person">
			<div>
				<h2>Grace Hopper</h2>
				<figure>
					<img src="images/Grace_Hopper_and_UNIVAC.jpg"
						alt="Grace Hopper at UNIVAC Console">
					<figcaption>Grace Hopper at UNIVAC Console</figcaption>
				</figure>
			</div>
			<p><strong>Inventor of the Compiler:</strong> Grace Hopper was a pioneering computer scientist
				and U.S. Navy rear admiral. She created the first compiler, which paved the way for
				high-level programming languages like COBOL. She helped popularize the concept of
				machine-independent programming languages.</p>
		</div>

		<div class="person">
			<div>
				<h2>Tim Berners-Lee</h2>
				<figure>
					<img src="images/Tim_Berners-Lee.jpg" alt="Tim Berners-Lee in 2005">
					<figcaption>Tim Berners-Lee in 2005</figcaption>
				</figure>
			</div>
			<p><strong>Inventor of the World Wide Web:</strong> Tim Berners-Lee created the World Wide Web
				in 1989, enabling the internet to become a global information-sharing platform. He also
				developed HTML, HTTP, and the first web browser. He continues to advocate for a free and
				open web.</p>
		</div>

		<div class="person">
			<div>
				<h2>Donald Knuth</h2>
				<figure>
					<img src="images/Donald_Ervin_Knuth_(cropped).jpg" alt="Knuth in 2011">
					<figcaption>Knuth in 2011</figcaption>
				</figure>
			</div>
			<p><strong>Pioneer in Algorithms and Programming Theory:</strong> Donald Knuth is famous for his
				deep work in algorithm analysis and for authoring <em>The Art of Computer
					Programming</em>. He also created TeX, a typesetting system widely used in
				scientific publishing.</p>
		</div>

		<div class="person">
			<div>
				<h2>Margaret Hamilton</h2>
				<figure>
					<img src="images/250px-Margaret_Hamilton_-_restoration.jpg"
						alt="Hamilton next to her Apollo 11 Software">
					<figcaption>Hamilton next to her Apollo 11 Software</figcaption>
				</figure>
			</div>
			<p><strong>Software Engineering Pioneer:</strong> Margaret Hamilton led the team that developed
				the onboard flight software for NASA’s Apollo missions. Her work was critical to the
				success of the moon landing. She also helped coin the term "software engineering" and
				emphasized the importance of rigorous coding practices.</p>
		</div>

		<div class="person">
			<div>
				<h2>John von Neumann</h2>
				<figure>
					<img src="images/Vonneumann-john_r.jpg" alt="Von Neumann's Los Alamos ID Badge">
					<figcaption>Von Neumann's Los Alamos ID Badge</figcaption>
				</figure>
			</div>
			<p><strong>Architect of the Modern Computer:</strong> John von Neumann developed the
				architecture underlying most modern computers, including the concept of stored programs.
				His contributions spanned mathematics, physics, and computing, shaping the early
				development of computer systems.</p>
		</div>

		<div class="person">
			<div>
				<h2>Dennis Ritchie</h2>
				<figure>
					<img src="images/Dennis_Ritchie_2011.jpg" alt="Ritchie in 2011">
					<figcaption>Ritchie in 2011</figcaption>
				</figure>
			</div>
			<p><strong>Creator of C and Co-developer of Unix:</strong> Dennis Ritchie created the C
				programming language and co-developed the Unix operating system, both of which have had
				lasting impacts on software development, operating systems, and modern computing
				infrastructure.</p>
		</div>

		<div class="person">
			<div>
				<h2>Linus Torvalds</h2>
				<figure>
					<img src="images/Lc3_2018_(263682303)_(cropped).jpeg" alt="Torvalds in 2018">
					<figcaption>Torvalds in 2018</figcaption>
				</figure>
			</div>
			<p><strong>Creator of Linux:</strong> Linus Torvalds created the Linux kernel in 1991, which
				grew into one of the most influential open-source projects. Linux now powers everything
				from servers and smartphones to embedded systems. Torvalds also developed Git, a widely
				used version control system.</p>
		</div>

	</section>

	<footer id="contact">
		<h3>Contact Me</h3>
		<a href="https://github.com/MikeShort11">GitHub</a>
		<a href="mailto:michael.short094@gmail.com">email</a>
	</footer>
	<script src="/scripts/script.js"></script>
	<script src="/scripts/theme.js"></script>

</body>

</html>
